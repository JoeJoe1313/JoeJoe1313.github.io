<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <link rel="stylesheet" type="text/css" href="/theme/css/elegant.prod.9e9d5ce754.css" media="screen">
        <link rel="stylesheet" type="text/css" href="/theme/css/custom.css" media="screen">
        <link rel="stylesheet" href="https://files.stork-search.net/basic.css">

        <link rel="dns-prefetch" href="//fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com/" crossorigin>

        <meta name="author" content="" />

        <meta property="og:type" content="article" />
        <meta name="twitter:card" content="summary">

<meta name="keywords" content="ai, ml, vlm, docker, fastapi, github-actions, Machine Learning, " />

<meta property="og:title" content="Image Segmentation with PaliGemma 2 mix, Transformers, Docker, FastAPI, and GitHub Actions "/>
<meta property="og:url" content="/app-docker-fastapi.html" />
<meta property="og:description" content="In today’s fast-paced machine learning landscape, deploying AI models is just as important as developing them. In this blog post, we are going to walk through an image segmentation application using Google’s PaliGemma 2 Mix model and transformers, containerized with Docker, and served through a FastAPI backend. We are also going to discuss the CI/CD pipeline using GitHub Actions to automate building the Docker image and pushing it to Docker Hub. Let’s explore this service, why we chose these technologies, and how you can get started and use the service yourself!" />
<meta property="og:site_name" content="JoJo&#39;s Blog" />
<meta property="og:article:author" content="" />
<meta property="og:article:published_time" content="2025-05-23T07:00:00+03:00" />
<meta name="twitter:title" content="Image Segmentation with PaliGemma 2 mix, Transformers, Docker, FastAPI, and GitHub Actions ">
<meta name="twitter:description" content="In today’s fast-paced machine learning landscape, deploying AI models is just as important as developing them. In this blog post, we are going to walk through an image segmentation application using Google’s PaliGemma 2 Mix model and transformers, containerized with Docker, and served through a FastAPI backend. We are also going to discuss the CI/CD pipeline using GitHub Actions to automate building the Docker image and pushing it to Docker Hub. Let’s explore this service, why we chose these technologies, and how you can get started and use the service yourself!">

        <title>Image Segmentation with PaliGemma 2 mix, Transformers, Docker, FastAPI, and GitHub Actions  · JoJo&#39;s Blog
</title>
        <link rel="shortcut icon" href="/theme/images/favicon.ico" type="image/x-icon" />
        <link rel="icon" href="/theme/images/apple-touch-icon-152x152.png" type="image/png" />
        <link rel="apple-touch-icon" href="/theme/images/apple-touch-icon.png"  type="image/png" />
        <link rel="apple-touch-icon" sizes="57x57" href="/theme/images/apple-touch-icon-57x57.png" type="image/png" />
        <link rel="apple-touch-icon" sizes="72x72" href="/theme/images/apple-touch-icon-72x72.png" type="image/png" />
        <link rel="apple-touch-icon" sizes="76x76" href="/theme/images/apple-touch-icon-76x76.png" type="image/png" />
        <link rel="apple-touch-icon" sizes="114x114" href="/theme/images/apple-touch-icon-114x114.png" type="image/png" />
        <link rel="apple-touch-icon" sizes="120x120" href="/theme/images/apple-touch-icon-120x120.png" type="image/png" />
        <link rel="apple-touch-icon" sizes="144x144" href="/theme/images/apple-touch-icon-144x144.png" type="image/png" />
        <link rel="apple-touch-icon" sizes="152x152" href="/theme/images/apple-touch-icon-152x152.png" type="image/png" />
        <link rel="apple-touch-icon" sizes="152x152" href="/theme/images/apple-touch-icon-180x180.png" type="image/png" />



    </head>
    <body>
        <div id="content">
            <div class="navbar navbar-static-top">
                <div class="navbar-inner">
                    <div class="container-fluid">
                        <a class="btn btn-navbar" data-toggle="collapse" data-target=".nav-collapse">
                            <span class="icon-bar"></span>
                            <span class="icon-bar"></span>
                            <span class="icon-bar"></span>
                        </a>
                        <a class="brand" href="/"><span class=site-name>JoJo's Blog</span></a>
                        <div class="nav-collapse collapse">
                            <ul class="nav pull-right top-menu">
                                <li >
                                    <a href=
                                       "/"
                                    >Home</a>
                                </li>
                                <li ><a href="/interests.html">Interests</a></li>
                                <li ><a href="/categories.html">Categories</a></li>
                                <li ><a href="/tags.html">Tags</a></li>
                                <li ><a href="/archives.html">Archives</a></li>
                                <li><form class="navbar-search" action="/search.html" onsubmit="return validateForm(this.elements['q'].value);">
                                    <input type="text" class="search-query" placeholder="Search" name="q" data-stork="site-search" autocomplete="off">
                                </form></li>
                            </ul>
                        </div>
                    </div>
                </div>
            </div>
            <div class="container-fluid">
                <div class="row-fluid">
                    <div class="span1"></div>
                    <div class="span10">
<article itemscope>
<div class="row-fluid">
    <header class="page-header span10 offset2">
        <h1>
            <a href="/app-docker-fastapi.html">
                Image Segmentation with PaliGemma 2 mix, Transformers, Docker, FastAPI, and GitHub Actions
            </a>
        </h1>
    </header>
</div>

<div class="row-fluid">
        <div class="span8 offset2 article-content">
            
            <p>In today’s fast-paced machine learning landscape, deploying AI models is just as important as developing them. In this blog post, we are going to walk through an image segmentation application using Google’s <strong>PaliGemma 2 Mix</strong> model and <strong>transformers</strong>, containerized with <strong>Docker</strong>, and served through a <strong>FastAPI</strong> backend. We are also going to discuss the CI/CD pipeline using <strong>GitHub Actions</strong> to automate building the Docker image and pushing it to Docker Hub. Let’s explore this service, why we chose these technologies, and how you can get started and use the service yourself!</p>
<p>The complete code is available on <a href="https://github.com/JoeJoe1313/PaliGemma-Image-Segmentation">GitHub</a>. Medium post can be found <a href="https://medium.com/@levchevajoana/image-segmentation-with-paligemma-2-mix-transformers-docker-fastapi-and-github-actions-ff6d00253832">here</a>.</p>
<h1>What is This Project All About?</h1>
<p>At its core, this project provides a <strong>FastAPI service</strong> that allows you to perform image segmentation using natural language. You simply provide as input to the REST API:</p>
<ul>
<li>A <strong>text prompt</strong> describing what to segment</li>
<li>An <strong>image</strong> via URL or file upload</li>
<li>The specific <strong>PaliGemma 2 model</strong> to perform image segmentation</li>
</ul>
<p>The service then returns:</p>
<ul>
<li>The base64 encoded <strong>model input image</strong></li>
<li>The base64 encoded segmentation <strong>masks</strong> clearly outlining the desired objects</li>
<li>The <strong>bounding box coordinates</strong> for each segmented object</li>
</ul>
<p>The <strong>FastAPI</strong> application is also containerized with <strong>Docker</strong> for consistent deployment across environments. A CI/CD pipeline with <strong>GitHub Actions</strong> is created for automated container builds and registry publishing to Docker Hub.</p>
<h1>Architectural Blueprint: How It All Works Together</h1>
<p>Understanding the flow of data and the interaction of components is key. Let’s first take a look at our project structure:</p>
<div class="highlight"><pre><span></span><code>project_folder/
├── app/
│   ├── __init__.py
│   ├── main.py            # FastAPI application and endpoints
│   └── segmentation.py    # Image segmentation logic
├── models/
│   ├── huggingface/       # Cache directory for Hugging Face models
│   └── vae-oid.npz        # VAE model for mask generation
├── .dockerignore
├── .github/
│   └── workflows/         # GitHub Actions for Docker build and push
│     └── docker-build.yml # Workflow to build and push Docker images
├── .gitignore
├── docker-compose.yml
├── Dockerfile
├── README.md
└── requirements.txt
</code></pre></div>

<h2>User &amp; Developer Workflow</h2>
<p>Our system is designed with both the end-user and the developer in mind.</p>
<figure>
    <pre class="mermaid">
        graph LR
            User([User]) -->|Provides Image & Prompt| ClientApp[Client Application]
            ClientApp -->|POST Request| FastAPI_Service[FastAPI Service]
            FastAPI_Service -->|Process Input| PaliGemma_Model[PaliGemma Model]
            PaliGemma_Model -->|Generate Segmentation Tokens| VAE_Model[VAE Model]
            VAE_Model -->|Decode Masks| FastAPI_Service
            FastAPI_Service -->|JSON Response | ClientApp
            ClientApp -->|Display Results| User

            Developer([Developer]) -->|Push Code| GitHubRepo[GitHub Repository]
            GitHubRepo -->|Trigger| GitHubActions[GitHub Actions]
            GitHubActions -->|Build & Push Image| DockerRegistry[Docker Hub]
            DockerRegistry -->|Pull Image| DeploymentEnv[Deployment Environment]
            DeploymentEnv -.->|Runs| FastAPI_Service
</pre>
    <figcaption style="text-align: center">Figure 1. User & Developer Workflow</figcaption>
</figure>

<p><strong>Figure 1</strong> shows the workflow:</p>
<ul>
<li>A <strong>User</strong> interacts with a client application, providing an image and a text prompt, and optionally the specific PaliGemma 2 model.</li>
<li>The <strong>Client Application</strong> sends an HTTP POST request to our <strong>FastAPI Service</strong>.</li>
<li>The <strong>FastAPI Service</strong> preprocesses the input and feeds it to the <strong>PaliGemma Model</strong>.</li>
<li>PaliGemma generates segmentation tokens, which are then passed to the <strong>VAE Model</strong>.</li>
<li>The VAE Model decodes these into pixel-level masks and, along with bounding boxes, sends them back to the API.
The API returns a JSON response to the client.</li>
</ul>
<p>To visualize the precise sequence of operations when a user requests an image segmentation, the following diagram details the interactions between the core components:</p>
<figure>
    <pre class="mermaid">
        sequenceDiagram
            participant User
            participant Client
            participant FastAPI
            participant SegmentationPy as segmentation.py
            participant PaliGemma as PaliGemma Model
            participant VAE as VAE Model

            User->>+Client: Upload image & prompt
            Client->>+FastAPI: POST /segment
            FastAPI->>+SegmentationPy: call segment_image()
            SegmentationPy->>+PaliGemma: infer with PaliGemma
            PaliGemma-->>-SegmentationPy: (tokens/features)
            SegmentationPy->>+VAE: generate masks
            VAE-->>-SegmentationPy: (pixel masks)
            SegmentationPy-->>-FastAPI: return mask & coords
            FastAPI-->>-Client: JSON response
            Client-->>-User: display results
</pre>
    <figcaption style="text-align: center">Figure 2. Segmentation process</figcaption>
</figure>

<p>This sequence highlights how FastAPI acts as the entry point, delegating the complex segmentation logic to the <code>segmentation.py</code> module, which in turn leverages the PaliGemma and VAE models to produce the desired output.</p>
<p>For <strong>developers</strong>, pushing code to GitHub triggers <strong>GitHub Actions</strong>, which automatically builds a Docker image and pushes it to a <strong>Container Registry</strong> (Docker Hub), ready for deployment.</p>
<h2>Inside the Application</h2>
<p>Within the Docker container, the application is neatly structured:</p>
<figure>
    <pre class="mermaid">
        graph TD
            subgraph "Docker Container"
                subgraph "app/"
                    main[main.py
                    FastAPI Application]
                    segmentation[segmentation.py
                    Image Segmentation Logic]
                    main -->|imports| segmentation
                end

                subgraph "External Dependencies"
                    NP[numpy]
                    TR[transformers]
                    PT[PyTorch]
                    JF[JAX/Flax]
                end

                subgraph "Models"
                    PaliGemma[PaliGemma 2 mix]
                    VAE[VAE Checkpoint]
                end

                segmentation -->|uses| TR
                segmentation -->|uses| PT
                segmentation -->|uses| JF
                segmentation -->|uses| NP

                main -->|loads| PaliGemma
                segmentation -->|loads| VAE
            end

            Client[Client Application] -->|HTTP Requests| main

            subgraph "API Endpoints"
                segment[POST /segment/]
                root[GET /]
            end

            main -->|defines| segment
            main -->|defines| root
            Client -->|calls| segment
            Client -->|calls| root

            style main fill:#c2e0ff,stroke:#0078d7
            style segmentation fill:#c2e0ff,stroke:#0078d7
            style Client fill:#ffd7b5,stroke:#ff8c00
            style segment fill:#d5e8d4,stroke:#82b366
            style root fill:#d5e8d4,stroke:#82b366
</pre>
    <figcaption style="text-align: center">Figure 3. Application Architecture</figcaption>
</figure>

<ul>
<li><code>app/main.py</code>: This is the heart of our API, built using FastAPI. It defines the API endpoints like <code>/</code> (for a welcome message) and <code>/segment</code> (for the actual segmentation).</li>
<li><code>app/segmentation.py</code>: This module contains all the core logic for image processing, interacting with the PaliGemma and VAE models, and generating the final masks and coordinates. It uses the libraries <strong>JAX</strong>, <strong>Flax</strong> and <strong>Transformers</strong> for efficient model execution and inference.</li>
</ul>
<h1>Technology Stack Overview</h1>
<p>Let’s first understand the key technologies used in the project.</p>
<h2>PaliGemma 2 mix</h2>
<p><a href="https://developers.googleblog.com/en/introducing-paligemma-2-mix/">PaliGemma 2 mix</a> is a state-of-the-art vision-language model from Google that can comprehend both images and text. It represents a significant advancement in multimodal AI, allowing for natural language-guided image understanding. Once PaliGemma identifies the segments (as tokens), a Variational Autoencoder (VAE) model steps in. It decodes these segmentation tokens into the detailed, pixel-level masks that you see as the output. This particular service uses a VAE checkpoint specifically <code>vae-oid.npz</code> for this task. A comprehensive overview of the image segmentation process with Paligemma 2 mix can be found in one of my previous posts <a href="https://joejoe1313.github.io/2025-04-15-paligemma-2-mix.html">here</a>.</p>
<h2>FastAPI</h2>
<p><a href="https://fastapi.tiangolo.com">FastAPI</a> is a web framework for building APIs with Python. We chose this framework for several compelling reasons:</p>
<ul>
<li>Automatic API documentation with <strong>Swagger UI</strong> and ReDoc
Data validation and serialization through <strong>Pydantic</strong> models</li>
<li>Asynchronous request handling with support for <code>async</code>/<code>await</code> syntax</li>
<li>Excellent performance comparable to Node.js and Go</li>
<li>Built-in dependency injection system</li>
<li>Security and authentication features out of the box</li>
<li>WebSocket support and background tasks</li>
</ul>
<p>In our project, <code>main.py</code> uses FastAPI to define the <code>/segment</code> endpoint which accepts form data including the prompt, and optionally an image URL or an uploaded image file, and the desired <code>model_id</code>.</p>
<h2>Transformers</h2>
<p><strong>Transformers</strong> is a library by <strong>Hugging Face</strong> that provides state-of-the-art pre-trained models for natural language processing and computer vision. For our project, it’s essential because:</p>
<ul>
<li>It provides easy access to the PaliGemma models</li>
<li>Offers a unified API for loading and using different model architectures</li>
<li>Handles model preprocessing and tokenization</li>
<li>Supports efficient model inference</li>
<li>Enables fine-tuning of models if needed</li>
</ul>
<h2>JAX/Flax</h2>
<p>JAX is a high-performance numerical computing library developed by Google. Flax is a neural network library built on top of JAX. Together, they provide:</p>
<ul>
<li>Accelerated computation on GPUs and TPUs</li>
<li>Just-in-time compilation for optimized performance</li>
<li>Automatic differentiation capabilities</li>
<li>Functional programming approach to machine learning</li>
</ul>
<p>In our app <strong>JAX/Flax &amp; Transformers</strong> are used for scalable model execution and inference, JAX/Flax is used for the VAE model which decodes segmentation tokens into pixel-level masks.</p>
<h2>Docker &amp; Docker Compose</h2>
<h3>What is Docker?</h3>
<p>Docker is a platform that uses OS-level virtualization to deliver software in packages called <strong>containers</strong>. A container is a standalone, executable package of software that includes everything needed to run an application: code, runtime, system tools, system libraries, and settings.</p>
<h3>Why Docker for This Project?</h3>
<ul>
<li><strong>Consistency</strong>: <em>“It works on my machine”</em> is a phrase Docker aims to eliminate. By packaging the application, its dependencies (like specific versions of PyTorch, JAX, Transformers), we ensure it runs identically everywhere - from a developer’s laptop to a production server.</li>
<li><strong>Isolation</strong>: Containers run in isolation, preventing conflicts between different applications or dependencies on the same host system.</li>
<li><strong>Simplified Deployment</strong>: Docker abstracts away the underlying infrastructure. With a simple <code>docker-compose up</code> command, anyone can get the service running without manually installing Python, various libraries, or configuring complex environments.</li>
<li><strong>Scalability</strong>: Dockerized applications are inherently easier to scale. Orchestration tools like Kubernetes can manage multiple instances of our container to handle increased load.</li>
<li><strong>Multi-Architecture Support</strong>: Our Docker setup supports both <code>amd64</code> (common for desktops and servers) and <code>arm64</code> (increasingly used in cloud instances and devices like Raspberry Pi) architectures, broadening its usability.</li>
</ul>
<h3>Key Docker Components Used:</h3>
<ul>
<li><strong><code>Dockerfile</code></strong></li>
</ul>
<p>This is the <strong>recipe for building our Docker image</strong>. It specifies the base image (e.g., a Python image), copies our application code (<code>app/</code> directory, <code>requirements.txt</code>, etc.) into the image, installs all necessary Python packages, and defines the command to run when the container starts (e.g., <code>uvicorn app.main:app</code>).</p>
<div class="highlight"><pre><span></span><code><span class="k">FROM</span><span class="w"> </span><span class="s">python:3.11-slim</span>

<span class="k">WORKDIR</span><span class="w"> </span><span class="s">/app</span>

<span class="k">COPY</span><span class="w"> </span>requirements.txt<span class="w"> </span>.
<span class="k">RUN</span><span class="w"> </span>pip<span class="w"> </span>install<span class="w"> </span>--no-cache-dir<span class="w"> </span>-r<span class="w"> </span>requirements.txt

<span class="k">COPY</span><span class="w"> </span>.<span class="w"> </span>.

<span class="k">ENV</span><span class="w"> </span><span class="nv">MODEL_ID</span><span class="o">=</span>google/paligemma2-3b-mix-448
<span class="k">ENV</span><span class="w"> </span><span class="nv">MODELS_DIR</span><span class="o">=</span>/app/models

<span class="k">EXPOSE</span><span class="w"> </span><span class="s">8000</span>

<span class="k">CMD</span><span class="w"> </span><span class="p">[</span><span class="s2">&quot;uvicorn&quot;</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;app.main:app&quot;</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;--host&quot;</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;0.0.0.0&quot;</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;--port&quot;</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;8000&quot;</span><span class="p">]</span>
</code></pre></div>

<ul>
<li><strong><code>docker-compose.yml</code></strong></li>
</ul>
<p>While a <code>Dockerfile</code> builds a single image, Docker Compose is used to define and run multi-container Docker applications. In our case, it simplifies running our FastAPI service. It can also manage networks, volumes, and other aspects of the application stack. For this project, it handles setting up the service and importantly, the volume mounting for model persistence.</p>
<div class="highlight"><pre><span></span><code><span class="nt">services</span><span class="p">:</span>
<span class="w">  </span><span class="nt">paligemma-api</span><span class="p">:</span>
<span class="w">    </span><span class="nt">image</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">joejoe1313/paligemma-image-segmentation:latest</span>
<span class="w">    </span><span class="nt">ports</span><span class="p">:</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="s">&quot;8000:8000&quot;</span>
<span class="w">    </span><span class="nt">environment</span><span class="p">:</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">MODEL_ID=google/paligemma2-3b-mix-448</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">MODELS_DIR=/app/models</span>
<span class="w">    </span><span class="nt">secrets</span><span class="p">:</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">hf_token</span>
<span class="w">    </span><span class="nt">volumes</span><span class="p">:</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">$HOME/.cache/huggingface/hub:/app/models/huggingface</span>
<span class="w">    </span><span class="nt">restart</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">unless-stopped</span>

<span class="nt">secrets</span><span class="p">:</span>
<span class="w">  </span><span class="nt">hf_token</span><span class="p">:</span>
<span class="w">    </span><span class="nt">file</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">$HOME/.cache/huggingface/token</span>
</code></pre></div>

<ul>
<li><strong><code>.dockerignore</code>:</strong></li>
</ul>
<p>Similar to <code>.gitignore</code>, this file lists files and directories that should not be copied into the Docker image during the build process (e.g., local virtual environments, <code>.git</code> directory). This keeps the image lean and build times faster.</p>
<h3>Smart Model Management with Volume Mounting</h3>
<p>Models, especially large ones like PaliGemma, take time to download. We use Docker’s <strong>volume mounting</strong> feature to map a directory on the host machine to a directory inside the container. This means:</p>
<ul>
<li>Models are downloaded once and <strong>persisted</strong> on your host machine.</li>
<li>They are <strong>reused</strong> across container restarts.</li>
<li>They can be <strong>shared</strong> if you run multiple instances.</li>
<li>Updating models becomes easier as you can manage them directly on your host.</li>
</ul>
<p>The default mount point in our <code>docker-compose.yaml</code> file is <code>$HOME/.cache/huggingface/hub:/app/models/huggingface</code> which maps the local <code>$HOME/.cache/huggingface/hub</code> directory to <code>/app/models/huggingface</code> in the container.</p>
<h2>CI/CD with GitHub Actions</h2>
<p>GitHub Actions provides automated workflows for continuous integration and continuous delivery (CI/CD). This is crucial for modern software development, thus we have implemented a CI/CD pipeline using <strong>GitHub Actions</strong>. We can see our workflow <code>.github/workflows/docker-build.yml</code> below:</p>
<div class="highlight"><pre><span></span><code><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Docker Build and Push</span>

<span class="nt">on</span><span class="p">:</span>
<span class="w">  </span><span class="nt">push</span><span class="p">:</span>
<span class="w">    </span><span class="nt">branches</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">main</span>
<span class="w">  </span><span class="nt">pull_request</span><span class="p">:</span>
<span class="w">    </span><span class="nt">branches</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">main</span>

<span class="nt">jobs</span><span class="p">:</span>
<span class="w">  </span><span class="nt">build</span><span class="p">:</span>
<span class="w">    </span><span class="nt">runs-on</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">ubuntu-latest</span>
<span class="w">    </span><span class="nt">steps</span><span class="p">:</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Login to Docker Hub</span>
<span class="w">        </span><span class="nt">uses</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">docker/login-action@v3</span>
<span class="w">        </span><span class="nt">with</span><span class="p">:</span>
<span class="w">          </span><span class="nt">username</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${{ vars.DOCKERHUB_USERNAME }}</span>
<span class="w">          </span><span class="nt">password</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${{ secrets.DOCKERHUB_TOKEN }}</span>

<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Set up QEMU</span>
<span class="w">        </span><span class="nt">uses</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">docker/setup-qemu-action@v3</span>

<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Set up Docker Buildx</span>
<span class="w">        </span><span class="nt">uses</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">docker/setup-buildx-action@v3</span>

<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">Build and push</span>
<span class="w">        </span><span class="nt">uses</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">docker/build-push-action@v6</span>
<span class="w">        </span><span class="nt">with</span><span class="p">:</span>
<span class="w">          </span><span class="nt">push</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${{ github.event_name != &#39;pull_request&#39; }}</span>
<span class="w">          </span><span class="nt">platforms</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">linux/amd64,linux/arm64</span>
<span class="w">          </span><span class="nt">tags</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">${{ vars.DOCKERHUB_USERNAME }}/paligemma-image-segmentation:latest</span>
</code></pre></div>

<p><strong>What does it do?</strong></p>
<ul>
<li><strong>Trigger</strong>: Every time code is pushed to the <code>main</code> branch (or a pull request is made to <code>main</code>), the GitHub Actions workflow is automatically triggered.</li>
<li><strong>Build</strong>: The workflow checks out the code and builds a multi-architecture (<code>amd64</code>/<code>arm64</code>) Docker image using the <code>Dockerfile</code>.</li>
<li><strong>Push</strong>: The newly built image is then pushed to a container registry (like Docker Hub).</li>
<li><strong>Tag</strong>: The image is tagged with the unique commit SHA (for traceability) and also with <code>latest</code> (for convenience).</li>
</ul>
<p><strong>Figure 4</strong> below shows a high level overview of the workflow:</p>
<figure>
    <pre class="mermaid">
        sequenceDiagram
            participant G as GitHub Repo
            participant A as GitHub Actions
            participant D as Docker Registry

            G->>A: on: push / pull_request to main
            activate A
            A-->>A: Login to Docker Registry
            A-->>A: Set up QEMU (for multi-arch)
            A-->>A: Set up Docker Buildx
            A-->>A: Build Docker image (multi-arch)
            A-->>D: Push image (tagged with SHA & latest)
            deactivate A
</pre>
    <figcaption style="text-align: center">Figure 4. GitHub Actions workflow</figcaption>
</figure>

<p><strong>How to use it in your fork</strong></p>
<p>If you fork this repository, you can set up your own CI/CD pipeline by adding the following secrets to your GitHub repository settings:</p>
<ul>
<li><code>DOCKERHUB_USERNAME</code>: Your Docker Hub username.</li>
<li><code>DOCKERHUB_TOKEN</code>: Your Docker Hub access token (not your password!).</li>
<li>You should also update the image in docker-compose.yaml with your username: <code>{DOCKERHUB_USERNAME}/paligemma-image-segmentation:latest</code></li>
</ul>
<p>This automated pipeline ensures that a fresh, deployable image is always available.</p>
<h1>Getting Started: Installation and Setup</h1>
<p>Ready to try it yourself? Here’s how:</p>
<h2>Prerequisites</h2>
<ul>
<li><strong>Docker</strong>: Ensure Docker Desktop or Docker Engine is installed and running.</li>
<li><strong>Hugging Face Token</strong>: To access gated models like PaliGemma, you’ll need a Hugging Face token. Make sure it’s stored at <code>$HOME/.cache/huggingface/token</code> on your host machine, or adjust the path accordingly. The application will use this token when downloading models.</li>
</ul>
<h2>Setup with Docker Compose:</h2>
<ul>
<li>Clone the repository:</li>
</ul>
<div class="highlight"><pre><span></span><code>git<span class="w"> </span>clone<span class="w"> </span>https://github.com/JoeJoe1313/PaliGemma-Image-Segmentation.git
<span class="nb">cd</span><span class="w"> </span>PaliGemma-Image-Segmentation
</code></pre></div>

<ul>
<li>Ensure your <strong>Hugging Face token</strong> is in place as mentioned above. The <code>docker-compose.yml</code> is set up to mount your local Hugging Face cache, including the token.</li>
<li>Run the application:</li>
</ul>
<div class="highlight"><pre><span></span><code>docker-compose<span class="w"> </span>up<span class="w"> </span>-d
</code></pre></div>

<blockquote>
<p><strong>Warning</strong>: It’s generally good practice to avoid running Docker commands as a root user unless necessary. Docker Compose should typically be run by a <code>user</code> in the <code>docker group</code>.</p>
</blockquote>
<p>This command will pull the pre-built Docker image and start the FastAPI service on <code>http://localhost:8000</code>. The <code>-dflag</code> runs it in detached mode.</p>
<h2>Choosing Your PaliGemma Model</h2>
<p>You have two ways to specify which PaliGemma model variant to use:</p>
<ul>
<li>At <strong>runtime via API</strong>: Pass the <code>model_id</code> parameter in your POST request to the <code>/segment</code> endpoint.</li>
<li>Via <strong>Docker Environment Variable</strong>: Set the <code>MODEL_ID</code> environment variable when starting the container.</li>
</ul>
<blockquote>
<p><strong>Note</strong>: If both are set, the <code>model_id</code> parameter in the API request takes precedence.</p>
</blockquote>
<p>If a specified model isn’t found in the local cache (<code>/app/models/huggingface</code> inside the container, which maps to your <code>$HOME/.cache/huggingface/hub</code>), the application will attempt to download it from Hugging Face. <strong>Figure 5</strong> below shows a comprehensive overview of the possible steps.</p>
<figure style="width: 70%; margin: auto;">
    <pre class="mermaid" style="max-width: 300px; margin: auto;">
        flowchart TD
            A[API Request] --> B{Check Local Cache}
            B -->|Found| H[Load from Local Cache]
            B -->|Not Found| C{Has HF Token?}

            %% Style definitions
            classDef process fill:#e0e0ff,stroke:#9999ff,color:black
            classDef decision1 fill:#ffe0b0,stroke:#ffbb66,color:black
            classDef decision2 fill:#d0f0d0,stroke:#aaddaa,color:black
            classDef cache fill:#d0e0ff,stroke:#aabbee,color:black

            %% Apply styles
            class A,D,F,I,E,Z process
            class B decision1
            class C decision2
            class G,H cache

            C -->|Yes| D[Authenticate with HF]
            C -->|No| E[Try Loading Public Model]
            D --> F[Download Model]
            F --> G[Save to Cache]
            E -->|Success| G
            E -->|Failure| Z[Auth Error]
            G --> H
            H --> I[Use Model]
</pre>
    <figcaption style="text-align: center">Figure 5. Model download scheme</figcaption>
</figure>

<h1>Examples: Putting the API to the Test</h1>
<p>Once the service is running (default: <code>http://localhost:8000</code>):</p>
<ul>
<li><strong>API Docs</strong>: Visit <code>http://localhost:8000/docs</code> for interactive API documentation.</li>
</ul>
<h2>Health Check (GET /)</h2>
<p>Verify the API is up and running.</p>
<p><strong>Request:</strong></p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">requests</span>

<span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;http://localhost:8000/&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">())</span>
</code></pre></div>

<p><strong>Response:</strong></p>
<div class="highlight"><pre><span></span><code><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;message&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Welcome to the PaliGemma Segmentation API!&quot;</span>
<span class="p">}</span>
</code></pre></div>

<h2>Segmenting an Image (POST /segment/)</h2>
<p>Form Parameters:</p>
<ul>
<li><code>prompt</code> (str, required): Text description of objects to segment (e.g., "segment the red car").</li>
<li><code>image_url</code> (str, optional): URL of the image to segment.</li>
<li><code>image_file</code> (UploadFile, optional): Uploaded image file to segment.</li>
<li><code>model_id</code> (str, optional): Specific PaliGemma model ID to use.</li>
</ul>
<h3>Using an Image URL</h3>
<figure>
    <pre class="mermaid">
        sequenceDiagram
            participant C as Client
            participant S as /segment Endpoint
            C->>S: POST Request with JSON body: { "image_url": "your_image_url.jpg", "prompt": "object to segment" }
            S-->>S: Download Image
            S-->>S: Process with PaliGemma & VAE
            S-->>C: JSON Response: { "image": "base64_input_image", "masks": [ { "mask": "base64_mask_data", "coordinates": [x_min,y_min,x_max,y_max] } ] }
    </pre>
    <figcaption style="text-align: center">Figure 6. Segment request</figcaption>
</figure>

<p><strong>Request:</strong></p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">requests</span>

<span class="n">data</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;prompt&quot;</span><span class="p">:</span> <span class="s2">&quot;segment left wheel&quot;</span><span class="p">,</span>
    <span class="s2">&quot;image_url&quot;</span><span class="p">:</span> <span class="s2">&quot;https://huggingface.co/datasets/huggingface/documentation-images/resolve/main/transformers/tasks/car.jpg&quot;</span>
<span class="p">}</span>

<span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">post</span><span class="p">(</span><span class="s2">&quot;http://localhost:8000/segment&quot;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">())</span>
</code></pre></div>

<h3>Uploading an Image File</h3>
<p><strong>Request:</strong></p>
<div class="highlight"><pre><span></span><code><span class="kn">import</span><span class="w"> </span><span class="nn">os</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">requests</span>

<span class="n">segm_url</span> <span class="o">=</span> <span class="s2">&quot;http://localhost:8000/segment&quot;</span>
<span class="n">image_path</span> <span class="o">=</span> <span class="s2">&quot;your_image.png&quot;</span>

<span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">image_path</span><span class="p">,</span> <span class="s2">&quot;rb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">image_file</span><span class="p">:</span>
    <span class="n">data</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;prompt&quot;</span><span class="p">:</span> <span class="s2">&quot;segment the main object&quot;</span> <span class="c1"># Adjust prompt as needed</span>
    <span class="p">}</span>
    <span class="n">files</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;image_file&quot;</span><span class="p">:</span> <span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">basename</span><span class="p">(</span><span class="n">image_path</span><span class="p">),</span> <span class="n">image_file</span><span class="p">,</span> <span class="s2">&quot;image/png&quot;</span><span class="p">)</span> <span class="c1"># Or image/jpeg</span>
    <span class="p">}</span>

    <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">post</span><span class="p">(</span><span class="n">segm_url</span><span class="p">,</span> <span class="n">files</span><span class="o">=</span><span class="n">files</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">data</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">())</span>
</code></pre></div>

<h3>Expected JSON Response Structure:</h3>
<p><strong>Response:</strong></p>
<div class="highlight"><pre><span></span><code><span class="p">{</span>
  <span class="s2">&quot;image&quot;</span><span class="p">:</span> <span class="s2">&quot;base64_encoded_model_input_image_data&quot;</span><span class="p">,</span>
  <span class="s2">&quot;masks&quot;</span><span class="p">:</span> <span class="p">[</span>
    <span class="p">{</span>
      <span class="s2">&quot;mask&quot;</span><span class="p">:</span> <span class="s2">&quot;base64_encoded_mask_data_for_object_1&quot;</span><span class="p">,</span>
      <span class="s2">&quot;coordinates&quot;</span><span class="p">:</span> <span class="p">[</span><span class="n">x_min</span><span class="p">,</span> <span class="n">y_min</span><span class="p">,</span> <span class="n">x_max</span><span class="p">,</span> <span class="n">y_max</span><span class="p">]</span>
    <span class="p">}</span>
    <span class="c1"># ...more masks if multiple instances of the prompt are found</span>
  <span class="p">]</span>
<span class="p">}</span>
</code></pre></div>

<p>See <a href="https://github.com/JoeJoe1313/PaliGemma-Image-Segmentation/blob/main/example.ipynb">example.ipynb</a> for a demonstration of the segmentation pipeline.</p>
<h1>Conclusion</h1>
<p>In this guide, we explored an image segmentation API using PaliGemma 2 mix, FastAPI, Transformers, and Docker. This service enables users to segment objects in images using natural language prompts, opening up a wide range of applications in computer vision, image editing, and data analysis. The containerized application provides a flexible, scalable solution that can be easily deployed across various environments. The combination of FastAPI’s performance and Docker’s portability makes this architecture ideal for production ML applications.</p>
<p><em>Happy coding!</em></p>


             
 
            
            
            







            <hr/>
        </div>
        <section id="article-sidebar" class="span2">
    <h4>Reading Time</h4>
    <p>~11 min read</p>
            <h4>Published</h4>
            <time itemprop="dateCreated" datetime="2025-05-23T07:00:00+03:00">Fri 23 May 2025</time>
        <h4>PaliGemma 2 Mix</h4>
    <ul class="multi-parts-list">
            <li >
            <a href="/paligemma-2-mix.html" title="Image Segmentation with PaliGemma 2 Mix and MLX">Part 1: Image Segmentation with PaliGemma 2 Mix and MLX</a>
            </li>
            <li  class="active-part">
            Part 2: Image Segmentation with PaliGemma 2 mix, Transformers, Docker, FastAPI, and GitHub Actions
            </li>
    </ul>
            <h4>Category</h4>
            <ul class="list-of-tags tags-in-article">
                <li>
                    <a class="category-link" href="/categories.html#machine-learning-ref">Machine Learning
                        <span class="superscript">10</span>
                    </a>
                </li>
            </ul>
            <h4>Tags</h4>
            <ul class="list-of-tags tags-in-article">
                <li><a href="/tags.html#ai-ref">ai
                    <span class="superscript">9</span>
</a></li>
                <li><a href="/tags.html#docker-ref">docker
                    <span class="superscript">1</span>
</a></li>
                <li><a href="/tags.html#fastapi-ref">fastapi
                    <span class="superscript">1</span>
</a></li>
                <li><a href="/tags.html#github-actions-ref">github-actions
                    <span class="superscript">1</span>
</a></li>
                <li><a href="/tags.html#ml-ref">ml
                    <span class="superscript">9</span>
</a></li>
                <li><a href="/tags.html#vlm-ref">vlm
                    <span class="superscript">5</span>
</a></li>
            </ul>
<h4>Stay in Touch</h4>
<div id="sidebar-social-link">
    <a href="https://github.com/JoeJoe1313" title="" target="_blank" rel="nofollow noopener noreferrer">
        <svg xmlns="http://www.w3.org/2000/svg" aria-label="GitHub" role="img" viewBox="0 0 512 512"><rect width="512" height="512" rx="15%" fill="#1B1817"/><path fill="#fff" d="M335 499c14 0 12 17 12 17H165s-2-17 12-17c13 0 16-6 16-12l-1-50c-71 16-86-28-86-28-12-30-28-37-28-37-24-16 1-16 1-16 26 2 40 26 40 26 22 39 59 28 74 22 2-17 9-28 16-35-57-6-116-28-116-126 0-28 10-51 26-69-3-6-11-32 3-67 0 0 21-7 70 26 42-12 86-12 128 0 49-33 70-26 70-26 14 35 6 61 3 67 16 18 26 41 26 69 0 98-60 120-117 126 10 8 18 24 18 48l-1 70c0 6 3 12 16 12z"/></svg>
    </a>
    <a href="https://www.linkedin.com/in/joana-levtcheva-479844164/" title="" target="_blank" rel="nofollow noopener noreferrer">
        <svg xmlns="http://www.w3.org/2000/svg" aria-label="LinkedIn" role="img" viewBox="0 0 512 512" fill="#fff"><rect width="512" height="512" rx="15%" fill="#0077b5"/><circle cx="142" cy="138" r="37"/><path stroke="#fff" stroke-width="66" d="M244 194v198M142 194v198"/><path d="M276 282c0-20 13-40 36-40 24 0 33 18 33 45v105h66V279c0-61-32-89-76-89-34 0-51 19-59 32"/></svg>
    </a>
    <a href="https://x.com/13_jo_jo_13" title="" target="_blank" rel="nofollow noopener noreferrer">
        <svg xmlns="http://www.w3.org/2000/svg" aria-label="Twitter" role="img" viewBox="0 0 512 512"><rect width="512" height="512" rx="15%" fill="#1da1f3"/><path fill="#fff" d="M437 152a72 72 0 0 1-40 12 72 72 0 0 0 32-40 72 72 0 0 1-45 17 72 72 0 0 0-122 65 200 200 0 0 1-145-74 72 72 0 0 0 22 94 72 72 0 0 1-32-7 72 72 0 0 0 56 69 72 72 0 0 1-32 1 72 72 0 0 0 67 50 200 200 0 0 1-105 29 200 200 0 0 0 309-179 200 200 0 0 0 35-37"/></svg>
    </a>
</div>
            





            





        </section>
</div>
</article>
<!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe.
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides.
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo https://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                      <div class="pswp__preloader__cut">
                        <div class="pswp__preloader__donut"></div>
                      </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div>
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>                    </div>
                    <div class="span1"></div>
                </div>
            </div>
        </div>
<footer>




    <div id="fpowered">
    </div>
</footer><div id="zoom-overlay" class="zoom-overlay" aria-hidden="true">
    <button type="button" class="zoom-overlay__close" aria-label="Close zoomed image">×</button>
    <img src="" alt="">
</div>            <script src="//code.jquery.com/jquery.min.js"></script>
        <script src="//netdna.bootstrapcdn.com/twitter-bootstrap/2.3.2/js/bootstrap.min.js"></script>
        <script src="/theme/js/elegant.prod.9e9d5ce754.js"></script>
        <script src="/theme/js/zoom-overlay.js"></script>
        <script>
            function validateForm(query)
            {
                return (query.length > 0);
            }
        </script>
        <script src="https://files.stork-search.net/releases/v1.6.0/stork.js"></script>
        <script src="/theme/js/stork-search.js"></script>

    <script>
    (function () {
        if (window.location.hash.match(/^#comment-\d+$/)) {
            $('#comment_thread').collapse('show');
        }
    })();
    window.onhashchange=function(){
        if (window.location.hash.match(/^#comment-\d+$/))
            window.location.reload(true);
    }
    $('#comment_thread').on('shown', function () {
        var link = document.getElementById('comment-accordion-toggle');
        var old_innerHTML = link.innerHTML;
        $(link).fadeOut(200, function() {
            $(this).text('Click here to hide comments').fadeIn(200);
        });
        $('#comment_thread').on('hidden', function () {
            $(link).fadeOut(200, function() {
                $(this).text(old_innerHTML).fadeIn(200);
            });
        })
    })
</script>

<script type="module">
    import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@11/dist/mermaid.esm.min.mjs';
    mermaid.initialize();
</script>    </body>
    <!-- Theme: Elegant built for Pelican
        License : MIT -->
</html>